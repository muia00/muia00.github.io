---
layout: post
title: GPT best practices GPT最佳实践
date: 2023-06-09 23:00:00
summary: 官方教你用GPT。
categories: 技术
comments: true
---

## 1.指令清晰


GPT无法读取您的思想。如果输出过长，请要求简短的回复。如果输出过于简单，请要求专家级的写作。如果您不喜欢格式，请展示您想要看到的格式。GPT需要猜测您想要什么的越少，您得到的可能性就越大。


**写详细，你要它做什么。** 如下图所示，左边是坏的例子，右边是好的例子。

<img src="{{ site.url }}/images/bad-and-good.png" />

**让模型以某个角色或者某种个性、风格输出。**


**使用分隔符清晰地表示输入的不同部分**。哪部分是参考的例子，哪部分是要它做的事情，哪部分是要求，用分隔符让它清楚，三引号，xml标签等都可以。


**指定完成任务所需的步骤。** 很多研究已经揭示，使用Chain-of-Thought prompting（CoT）可以帮助大型语言模型（LLMs）更好地解决涉及数学或推理的复杂任务。大白话就是让它和以前写数学证明一样，一步一步地推导。参考[奖励过程而不是结果](https://muia00.github.io/2023-06-01/focus-on-the-journey.html)


**提供示例。**

<img src="{{ site.url }}/images/example.png" />


**指定所需输出的长度。** 多少字，多少句，多少段等。




## 2.提供参考文本


**让模型使用参考文本回答。**


+ 对于长度比较短的文本，可以直接把文本输入模型，让模型根据文本内容输出。


+ 对较长的文本，由于模型上下文token数有限制，需要使用基于嵌入式的查询来实现目的。嵌入式查询的基本步骤如下：


> 参考文本向量化:将长文本切片，利用OpenAI的Embedding模型将切片的文本转化为向量，存储到本地或云端向量数据库。用户查询向量化：将用户查询使用同样方法向量化。向量相似性搜索：将2的向量和1的向量进行比对（余弦相似度），得到相似向量及其文本。调用GPT：将问题和3得到的文本，以及其他一些prompt指令一起，发送给GPT，返回结果。


**让模型回答问题的时候提供其引用的文本片段。**




## 3.将复杂的任务分解


**使用意图分类来识别用户查询的最相关指令。**


即先对用户的查询使用GPT进行分类，再针对每一类分别设置处理指令，而不是把他们都混在一起进行查询处理。这样做会让结果更精确，同时因为不需要一次发送包含所有情况描述的指令，也可以节省开销。


对于需要进行非常长时间对话的应用程序，**对先前的对话进行总结或过滤**。这样做的好处是在有限的上下文窗口内尽可能保留历史信息。


**将长文档逐段概括，并递归构建完整的摘要。**


要总结一本非常长的文档，比如一本书，我们可以使用一系列查询来总结文档的每个部分。可以将各个部分的摘要连接起来并进行总结，从而产生摘要的摘要。这个过程可以递归进行，直到整个文档被总结。如果需要使用早期部分的信息来理解后期部分，那么一个有用的进一步技巧是在总结该点的内容时，包括在书中给定点之前的文本的运行摘要。见这项研究：[Summarizing books with human feedback ](https://openai.com/research/summarizing-books)




## 4.给GPT一些“思考”时间


**指导模型在从第一原理出发进行推理，而不是直接给出结论**，可以获得更好的结果。


让模型仍然一步一步推理获得答案，但是把**推理过程对用户隐藏，只给出相应提示**，引导用户正确解答问题。这个例子主要用在教学场合。


**让模型确认是否有遗漏信息。**




## 5.使用外部工具


**使用基于嵌入的搜索，见第2点。**


**编写代码来计算，甚至调用外部API。**




## 6.系统地评估性能


好的评估是：


- 贴近现实应用的，多样的。


+ 测试样例足够多，有统计显著性。


- 易于自动化。

